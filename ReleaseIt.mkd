Release It! - Michael Nygard
---------------------------

## Introduction
* First your system needs to have Stability. Lack of Stability means short-term fixes, emergencies, "excitement", and daily fires
* Once gaining Stability, you need Capacity, being able to handle loads and increase in volume of uses in your system
* Good designs are more resilient than bad, and designing for network and storage usage have sets of challenges to account for
* You must have visibility into your system, in prod, QA, etc, and the system should be transparent and produce useful reporting that leads to actionable troubleshooting

## Stability
1. The exception that grounded an Airline
1. Introducing Stability
1. Stability AntiPatterns
1. Stability Patterns
1. Stability summary

## Capacity
1. Trampled by your own customers
1. Introducing Capacity
1. Capacity AntiPatterns
1. Capacity Patterns

## General Design Issues
1. Networking
  * Multihomed servers - servers that exist in multiple networks, therefore have multiple network interfaces
    + separate interfaces for separate purposes - separate prod facing from nonprod facing, could have multiple prod facing for load balencing or for failover. 
    + be aware that a multihomed server will probably have multiple different DNS entries that point to it, and they'll probably be different than its own hostname
    + bonded, or teaming interfaces - multiple network interfaces having the same IP - can be used to balance traffic, but beware that you do extra config to make sure you don't introduce routing loops
    + Nonprod facing interfaces should be used for backups, and for admin access (like SSH), and *don't go through prod*
    + Applications should be written so that it is aware of its own name/IP and should know what specific interfaces it should connect to when reaching the server. Danger being that if its aware of which interfaces, it could connect to any on the server, which may cross prod-facing to admin-facing
  * Routing
    + Decide what interfaces should be prod/ nonprod, keep the routes each should take separate, facing different VLANs, and keep records of the routing configuration (destination name, address, and desired route)
  * Virtual IP Addresses - Utilizing clustering
    + Clustering uses software that assigns a virtual IP to one server, and where app traffic is sent to a DNS name that points to the virtual IP. If the server is to be shutdown, or experiences failure (say through loss of a heartbeat to the clustering switch), the cluster switch will assign the virtual IP address to a new server on standby.
    + In-memory state that is not made persistent will be lost (remember this could be an app server or a DB server). Client's that use clustered services should be written to handle sudden loss of connectivity. Catch an exception, attempt to reconnect, but be prepared to "circuit break"
1. Security
  * Principle of Least Privilege - the privilege of a process should only have as much privilege as it needs to complete its job, and no more. Never run as root or admin unless it's absolutely necessary, keep its use to a minimum. Relegate long running processes to separate users, like the "apache" user for Apache. Load balancers can add as a separator between an exposed port under 1024, which could be open for a UNIX app needing root, and reassigned ports to the load balanced machines
  * Configured Passwords - separate passwords to DB's from any other config files, and should definitely not live in the installation directory. Should be readable only to the file owner. If passwords are kept in memory, they can be recoverable through a memory dump, maybe through a kernel error that dumps its memory. Encrypt password files, but try to use software to monitor changes to those files.
1. Availability
  * Calculating downtime and availability costs - availability as a percentage (98%, 99% 99.999%), take a 30 day month for minutes, multiply by availability for uptime
  * Figure how much your site makes in an hour during peak. Worst case loss because of availability is peak money times downtime. There's a big difference between 98% and 99.99%
  * Each '9' of availability increases implementation costs by a factor of ten and operational cost per year by a factor of two
  * Nip future SLA (dis)agreements by writing precise SLA's early.
    + define by how up are critical features, specific features, or services of your app
    + You cannot offer a higher SLA than the lowest SLA of the service your app uses (ie, third party services)
    + Have an automated system reporting on your systems availability, and have it monitor your critical services
    + Define what good responses from your system are like, ie timeouts, too slow, throwing errors
      - How often will automation perform synthetic transactions?
      - Max acceptable response time from each step of system
      - What response codes indicate success, and what codes indicate failure?
      - where will the data be recorded?
      - what formula will be used to compute availability? Based on time, or number of samples?
  * Horizontal scaling and load balancing
    + DNS Round-Robin - oldest of load balancing, avoid doing this today
      - DNS servers resolve requests by rotating through IPs of app servers
      - Points requests directly to app servers, not good security
      - DNS servers don't account for app server health, and doesn't guarantee load is distributed evenly
      - DNS is subject to caching the IP
    + Reverse Proxy
      - The difference between a regular Proxy server and a Reverse Proxy
        * Regular proxies multiplex many outgoing requests into a single source IP
        * Reverse proxies multiplex incoming requests for a single source IP to many addresses
      - Reverse proxies can cache static content
      - Since reverse proxies get involved in every request, reverse proxy servers can quickly become overburdened
      - Many reverse proxies may not take into account app server health
    + Hardware load balancing - hardware that serve a similar role to reverse proxies
      - Can often check health of app servers and remove bad servers from the active pool
      - Can often switch through any connection based protocal
      - Can make managing SSL and certs more difficult, including choosing where SSL decryption happens
      - Probably very expensive
    + Clustering
      - Servers that are aware of each other and talk to each other for load balancing and server health
      - Load balancing: active/active
      - Redundancy for failure: active/passive
      - Some applications may have built-in clustering services, where there isn't, you can run an app under a clustering server, and can be configured to perform specific actions when app health is down
      - Clustering servers/server software may be finicky to configure and may have unique sets of quirks
      - Isn't known for scaling well, and can be used to band-aid on clustering support
1. Administration
  * An easy-to-administrate system is a happy system, and leads to happy admins and users. How can you make your system at large easier to admin?
  * Making QA match Prod
    + According to Nygard, the most influential differences between Prod and QA tend to not be configuration differences, but *Topology* differencies
    + Topology - the number and connectivity of servers and applications. Produce diagrams of your Topology of your System, across your environments. Other environments should mimic prod's topology
    + Keep your environments separated! Utilize different machines or relegate separation with VM's.
    + Practice the Zero, One, Many rule in differences between environments. In prod, you may have zero, one, or many of a given resource in your topology. If you must scale down other environments compared to prod, at least make sure your copy environment matches the zero, one, or many instances in its topology. Never have only one of a resource in nonprod when there's many in prod
    + Do you have firewalls and load balancers in prod? Your copy environments ( **including dev!** ) must have them also at the same topology points, at the very least cheaper versions of prod. Make sure you have firewalls in place day one in dev also, avoid introducing them after development has already started
  * Configuration Files
    + Property files - config files that will change between environments, deployments
    + Plumbing files - config files that should never be edited by hand, files that hold object associations, files that internally wire your application to itself
    + Admins should never be able to touch plumbing and break object associations
    + Plumbing should be kept separate (different files, different directories, etc) from Property
    + Production config (property) should be kept in a different directory than the app install directory since the install dir will probably be overwritten as some point
    + The author recommends Admins use version control on configuration files for environments that are in secure repos, a part of a larger change control process, a part of automated deployments that go directly to the repo, and have an automated audit process
    + Configuration properties should be crystal clear in what values they hold so anyone working on editing them shouldn't have to guess making changes
    + **Name properties by their function, not their nature** - don't name by what something is, name by what it does or means. Try to think of "what kind of thing is this?" rather than just "what is this?"`
  * Startup and Shutdown
    + Apps need to report errors on things that fail during startup, and needs to be aware and react accordingly if things fail during startup 
    + Apps need to ensure all of its components are loaded properly before accepting connections/ any new work
    + if an app requires a connection pool, the connection pool needs to verify it's made successful connections on initialization, otherwise it needs to report it's in a failure state, and the entire app should be in a failure state (not accepting new work, but perhaps still able to be examined)
    + Clean shutdowns should not be rude to customers in the store. During shutdown, the app needs to not accept new work, but handle existing tasks by either working them to completion, or delegate work to others before closing (but temper this with a timeout so unnecessarily long customers get kicked out eventually)
  * Administrative Interfaces
    + GUI's are ok, but cli's are often so much more powerful and versatile (can be scripted, front-ended, works over ssh, can wrap in logging)
    + Web interfaces (HTML pages, REST apis) are useful, and more versatile than straight OS clients since you could use HTTP scripting to automate actions or write clients against them, but cli's are still awesome and shouldn't be forgotten
1. Design summary
  * Define application / system architecture early to make everyone's lives easier, changes further down the road will be harder to deal with.
## Operations
1. Phenomenal Cosmic Powers, Itty-Bitty Living space
1. Transparency
1. Adaptation

